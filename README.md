# Himalayan Expeditions Dataset Analysis

Лабораторная работа по анализу **реального датасета** экспедиций в Гималаи с применением методов машинного обучения и статистического анализа.

## Описание проекта

Данный проект реализует комплексный анализ **реального датасета Himalayan Expeditions с Kaggle**, включающий:

1. **Загрузку реальных данных** - автоматическая загрузка с Kaggle через API
2. **Исследование данных** - адаптивный анализ структуры реального датасета  
3. **Разделение на выборки** - создание train/test выборок с интеллектуальной стратификацией
4. **Очистку от выбросов** - использование Isolation Forest для обнаружения аномалий
5. **Визуализацию данных** - построение scatter plots с категориальной окраской
6. **Построение гистограмм** - анализ распределений числовых переменных по категориям
7. **Генерацию точек** - создание синтетических данных с многомерным нормальным распределением
8. **Модель смешанного Гауссова распределения** - продвинутое моделирование данных

## Структура проекта

```
├── digital_culture.py          # Основной модуль анализа
├── download_real_data.py       # Загрузка реальных данных с Kaggle
├── create_demo_dataset.py      # Генератор демонстрационного датасета (резерв)
├── requirements.txt            # Зависимости проекта (включая kagglehub)
└── README.md                   # Документация
```

## Установка и запуск

### 1. Установка зависимостей

```bash
pip install -r requirements.txt
```

### 2. Загрузка реального датасета

```bash
python download_real_data.py
```

### 3. Запуск анализа

```bash
python digital_culture.py
```

## Описание реальных данных

Реальный датасет Himalayan Expeditions содержит информацию о тысячах экспедиций в Гималаи. Структура данных автоматически анализируется и адаптируется в зависимости от доступных колонок.

### Типичные характеристики датасета

**Числовые переменные:**
- Высота пиков
- Количество участников экспедиции  
- Возраст участников
- Даты экспедиций
- Высота базовых лагерей
- Продолжительность экспедиций

**Категориальные переменные:**
- Названия пиков
- Сезоны экспедиций
- Национальности участников
- Результаты экспедиций (успех/неудача)
- Причины завершения экспедиций
- Маршруты восхождений

## Методология анализа

### 1. Адаптивный анализ данных
- Автоматическое определение типов колонок
- Интеллектуальный поиск ключевых переменных
- Обработка различных форматов данных
- Статистический анализ с учетом специфики данных

### 2. Умная предобработка
- Разделение с автоматической стратификацией по целевым переменным
- Адаптивное обнаружение выбросов под структуру данных
- Интеллектуальная обработка пропущенных значений

### 3. Продвинутая визуализация
- Автоматический выбор осей для scatter plots
- Ограничение категорий для читаемости графиков
- Гистограммы с группировкой по ключевым факторам
- Сравнительная визуализация оригинальных и сгенерированных данных

### 4. Генерация данных на основе многомерного нормального распределения
- **Автоматический поиск** подходящих колонок (height/weight аналоги)
- **Раздельное моделирование** по категориям (пол/сезон/тип экспедиции)
- **Вычисление ковариационных матриц** для каждой категории
- **Генерация новых точек** с сохранением статистических свойств
- **Оценка качества** через логарифм правдоподобия

### 5. Модель смешанного Гауссова распределения
- Кластеризация данных на компоненты
- Генерация из смешанного распределения
- Анализ вероятностей принадлежности

## Основные классы

### HimalayanExpeditionsAnalyzer
Адаптивный анализатор для реальных данных:
- `load_data()` - умная загрузка с автопоиском файлов
- `_identify_column_types()` - автоматическое определение типов данных
- `explore_data()` - адаптивный исследовательский анализ
- `split_data()` - разделение с интеллектуальной стратификацией
- `detect_outliers()` - адаптивное обнаружение выбросов
- `visualize_data()` - умная визуализация
- `plot_histograms()` - построение информативных гистограмм

### PointGenerator  
Генератор на основе многомерного нормального распределения:
- `fit()` - обучение с автопоиском колонок и категорий
- `generate_points()` - генерация новых точек
- `log_likelihood()` - вычисление логарифма правдоподобия
- `mean_log_likelihood()` - усредненная метрика качества

### GaussianMixtureAnalyzer
Анализ смешанных распределений:
- `fit()` - обучение модели смешанного Гауссова распределения
- `generate_points()` - генерация из смешанного распределения
- `predict_proba()` - вероятности принадлежности к компонентам

## Преимущества работы с реальными данными

1. **Реалистичность** - работа с настоящими данными экспедиций
2. **Масштабность** - тысячи записей для статистически значимых выводов
3. **Разнообразие** - множество различных факторов и переменных
4. **Практическая ценность** - результаты можно применить для планирования экспедиций
5. **Научная значимость** - анализ может выявить новые закономерности

## Результаты анализа

Анализ реальных данных позволяет выявить:
- **Факторы успеха экспедиций** - влияние опыта, размера команды, сезона
- **Временные тренды** - изменение успешности восхождений по годам
- **Географические паттерны** - различия между пиками и регионами
- **Сезонные закономерности** - оптимальные времена для восхождений
- **Влияние технологий** - роль современного оборудования и кислорода
- **Демографические факторы** - влияние возраста, национальности, опыта

## Технические требования

- Python 3.7+
- pandas >= 1.3.0
- numpy >= 1.21.0  
- matplotlib >= 3.5.0
- seaborn >= 0.11.0
- scikit-learn >= 1.0.0
- scipy >= 1.7.0
- **kagglehub >= 0.1.0** (для загрузки данных)

## Работа с Kaggle API

Для загрузки данных с Kaggle требуется:

1. **Учетная запись Kaggle** - зарегистрируйтесь на kaggle.com
2. **API токен** - скачайте kaggle.json из настроек аккаунта
3. **Настройка аутентификации** - поместите токен в нужную директорию

Подробная инструкция: https://github.com/Kaggle/kaggle-api

## Пример использования

```python
from digital_culture import HimalayanExpeditionsAnalyzer, PointGenerator

# Создаем анализатор
analyzer = HimalayanExpeditionsAnalyzer()

# Загружаем реальные данные (автоматический поиск)
analyzer.load_data()

# Проводим полный анализ
analyzer.explore_data()
analyzer.split_data()
analyzer.detect_outliers()
analyzer.visualize_data()
analyzer.plot_histograms()

# Создаем генератор точек
generator = PointGenerator()
generator.fit(analyzer.clean_data)

# Генерируем новые данные
generated_points = generator.generate_points(n_points=100)
print("Качество модели:", generator.mean_log_likelihood(analyzer.test_data))
```

## Лицензия

Проект создан в образовательных целях для демонстрации методов анализа реальных данных и машинного обучения. Используются открытые данные с Kaggle. 